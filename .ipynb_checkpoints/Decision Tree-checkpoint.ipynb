{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Load the CSV file into a RDD\n",
    "irisData = sc.textFile(\"data/iris.csv\")\n",
    "irisData.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Remove the first line (contains headers)\n",
    "dataLines = irisData.filter(lambda x: \"Sepal\" not in x)\n",
    "dataLines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def transformToNumeric( inputStr) :\n",
    "    attList=inputStr.split(\",\")\n",
    "    \n",
    "    #Set default to setosa\n",
    "    irisValue=1.0\n",
    "    if attList[4] == \"versicolor\":\n",
    "        irisValue=2.0\n",
    "    if attList[4] == \"virginica\":\n",
    "        irisValue=3.0\n",
    "       \n",
    "    #Filter out columns not wanted at this stage\n",
    "    values= Vectors.dense([ irisValue, \\\n",
    "                     float(attList[0]),  \\\n",
    "                     float(attList[1]),  \\\n",
    "                     float(attList[2]),  \\\n",
    "                     float(attList[3])  \\\n",
    "                     ])\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Change to a Vector\n",
    "irisVectors = dataLines.map(transformToNumeric)\n",
    "irisVectors.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Perform statistical Analysis\n",
    "from pyspark.mllib.stat import Statistics\n",
    "irisStats=Statistics.colStats(irisVectors)\n",
    "irisStats.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "irisStats.variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "irisStats.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "irisStats.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Statistics.corr(irisVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Transform to a Data Frame for input to Machine Learing\n",
    "#Drop columns that are not required (low correlation)\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def transformToLabeledPoint(inStr) :\n",
    "    attList=inStr.split(\",\")\n",
    "    lp = ( attList[4], Vectors.dense([attList[0],attList[2],attList[3]]))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "irisLp = dataLines.map(transformToLabeledPoint)\n",
    "irisDF = sqlContext.createDataFrame(irisLp,[\"label\", \"features\"])\n",
    "irisDF.select(\"label\",\"features\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Find correlations\n",
    "numFeatures = irisDF.take(1)[0].features.size\n",
    "labelRDD = irisDF.map(lambda lp: lp.label)\n",
    "for i in range(numFeatures):\n",
    "    featureRDD = irisDF.map(lambda lp: lp.features[i])\n",
    "    corr = Statistics.corr(labelRDD, featureRDD, 'pearson')\n",
    "    print('%d\\t%g' % (i, corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Indexing needed as pre-req for Decision Trees\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "stringIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexed\")\n",
    "si_model = stringIndexer.fit(irisDF)\n",
    "td = si_model.transform(irisDF)\n",
    "td.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Split into training and testing data\n",
    "(trainingData, testData) = td.randomSplit([0.9, 0.1])\n",
    "trainingData.count()\n",
    "testData.count()\n",
    "testData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create the model\n",
    "dtClassifer = DecisionTreeClassifier(maxDepth=2, labelCol=\"indexed\")\n",
    "dtModel = dtClassifer.fit(trainingData)\n",
    "\n",
    "dtModel.numNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dtModel.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Predict on the test data\n",
    "predictions = dtModel.transform(trainingData)\n",
    "predictions.select(\"prediction\",\"indexed\",\"label\",\"features\").collect()\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \\\n",
    "                    labelCol=\"indexed\",metricName=\"precision\")\n",
    "evaluator.evaluate(predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Draw a confusion matrix\n",
    "labelList=predictions.select(\"indexed\",\"label\").distinct().toPandas()\n",
    "predictions.groupBy(\"indexed\",\"prediction\").count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
